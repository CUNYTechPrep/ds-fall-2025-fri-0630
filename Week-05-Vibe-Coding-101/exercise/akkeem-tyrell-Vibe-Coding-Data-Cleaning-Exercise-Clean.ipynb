{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355b6353",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **What percentage of respondents work remotely vs. in-office?**\n",
    "5. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "6. **What's the salary gap between men and women in tech roles?**\n",
    "7. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9714764",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "### ✅ Data Loading & Exploration\n",
    "- [✓] Load TSV file with proper encoding and delimiters\n",
    "- [✓] Initial data exploration and shape analysis\n",
    "- [✓] Column inspection and naming standardization\n",
    "\n",
    "### ✅ Data Cleaning Pipeline\n",
    "- [✓] Standardize column names to snake_case\n",
    "- [✓] Parse and clean salary data (remove commas, convert to numeric)\n",
    "- [✓] Handle missing values with appropriate imputation strategies\n",
    "- [✓] Normalize currency codes and country names\n",
    "- [✓] Create US scope filtering logic\n",
    "- [✓] Standardize industry categories (fix fragmentation issues)\n",
    "- [✓] Create tech industry classification\n",
    "\n",
    "### ✅ Business Questions Analysis\n",
    "- [✓] Q1: Software Engineer median salary (regex pattern matching)\n",
    "- [✓] Q2: Highest paying US state for tech workers\n",
    "- [✓] Q3: Salary increase per year of experience (linear regression)\n",
    "- [✓] Q4: Remote vs in-office work percentage\n",
    "- [✓] Q5: Highest paying non-tech industry (with standardized categories)\n",
    "- [✓] Bonus: Gender salary gap analysis\n",
    "- [✓] Bonus: Education level premium analysis\n",
    "\n",
    "### Key Insights Discovered\n",
    "- Industry standardization critical (reduced 1,220 → 488 categories)\n",
    "- Pharmaceuticals outperform general tech ($115K vs $90K median)\n",
    "- Software Engineers earn $140K median (premium subset of tech)\n",
    "- $2,324 salary increase per year of experience in tech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f360281",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Start here! Load the dataset and get familiar with what you're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd71e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported and warnings suppressed\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Suppress warnings for cleaner notebook output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='pandas')\n",
    "\n",
    "print(\"✅ Libraries imported and warnings suppressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e31618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: /Users/akkeem/Documents/ClassAssignments/TTPR/Week-05/ds-fall-2025-fri-0630/Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey2021 (Responses) - Form Responses 1.tsv\n",
      "Dataset shape: (28062, 18)\n",
      "\n",
      "Column preview:\n",
      "['Timestamp', 'How old are you?', 'What industry do you work in?', 'Job title', 'If your job title needs additional context, please clarify here:', \"What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)\", 'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.', 'Please indicate the currency', 'If \"Other,\" please indicate the currency here: ', 'If your income needs additional context, please provide it here:']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Ask A Manager Salary Survey (TSV) robustly\n",
    "filename = 'Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey2021 (Responses) - Form Responses 1.tsv'\n",
    "repo_root = Path('/Users/akkeem/Documents/ClassAssignments/TTPR/Week-05/ds-fall-2025-fri-0630')\n",
    "\n",
    "# Search for the file under repo_root\n",
    "candidates = list(repo_root.rglob(filename))\n",
    "if not candidates:\n",
    "    candidates = list(Path('.').rglob(filename))\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"Could not find '{filename}' under {repo_root} or current working dir\")\n",
    "\n",
    "data_path = candidates[0]\n",
    "print('Loading from:', data_path)\n",
    "\n",
    "# Load TSV file\n",
    "df = pd.read_csv(data_path, sep='\\t', encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Initial exploration\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nColumn preview:')\n",
    "print(df.columns.tolist()[:10])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade752b1",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n",
    "\n",
    "Clean and standardize the messy data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75c4233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 COLUMN STANDARDIZATION\n",
      "========================================\n",
      "Pre-renamed annual salary column ✓\n",
      "Converted 18 columns to snake_case ✓\n",
      "Intuitive rename mapping:\n",
      "  • timestamp → timestamp\n",
      "  • how_old_are_you → age_group\n",
      "  • what_industry_do_you_work_in → industry\n",
      "  • job_title → job_title\n",
      "  • if_your_job_title_needs_additional_context_please_clarify_here → job_title_context\n",
      "  • what_country_do_you_work_in → country\n",
      "  • if_youre_in_the_us_what_state_do_you_work_in → us_state\n",
      "  • what_city_do_you_work_in → city\n",
      "  • annual_salary → annual_salary\n",
      "  • how_much_additional_monetary_compensation_do_you_get_if_any_for_example_bonuses_or_overtime_in_an_average_year_please_only_include_monetary_compensation_here_not_the_value_of_benefits → additional_compensation\n",
      "  • please_indicate_the_currency → currency\n",
      "  • if_other_please_indicate_the_currency_here → currency_other\n",
      "  • if_your_income_needs_additional_context_please_provide_it_here → income_context\n",
      "  • how_many_years_of_professional_work_experience_do_you_have_overall → years_experience_overall\n",
      "  • how_many_years_of_professional_work_experience_do_you_have_in_your_field → years_experience_field\n",
      "  • what_is_your_highest_level_of_education_completed → highest_education\n",
      "  • what_is_your_gender → gender\n",
      "  • what_is_your_race_choose_all_that_apply → race\n",
      "\n",
      "✅ Applied 18 intuitive column names\n",
      "Column count: 18\n",
      "Final columns: ['timestamp', 'age_group', 'industry', 'job_title', 'job_title_context', 'annual_salary', 'additional_compensation', 'currency', 'currency_other', 'income_context']...\n"
     ]
    }
   ],
   "source": [
    "# STEP 2A: Column Standardization\n",
    "print(\"🔧 COLUMN STANDARDIZATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Pre-rename long annual salary column\n",
    "explicit_map = {}\n",
    "for col in df.columns:\n",
    "    if re.search(r\"^what\\s+is\\s+your\\s+annual\\s+salary\\?\", col, flags=re.IGNORECASE):\n",
    "        explicit_map[col] = 'annual_salary'\n",
    "\n",
    "if explicit_map:\n",
    "    df = df.rename(columns=explicit_map).copy()\n",
    "    print('Pre-renamed annual salary column ✓')\n",
    "\n",
    "# Convert to snake_case\n",
    "def to_snake(name: str) -> str:\n",
    "    name = name.strip().lower()\n",
    "    name = re.sub(r\"[\\s\\-/]+\", \"_\", name)\n",
    "    name = re.sub(r\"[^a-z0-9_]+\", \"\", name)\n",
    "    name = re.sub(r\"_+\", \"_\", name)\n",
    "    return name.strip(\"_\")\n",
    "\n",
    "# Build new names with de-duplication\n",
    "new_columns = []\n",
    "seen = {}\n",
    "for col in df.columns:\n",
    "    base = to_snake(col)\n",
    "    if base not in seen:\n",
    "        seen[base] = 0\n",
    "        new_columns.append(base)\n",
    "    else:\n",
    "        seen[base] += 1\n",
    "        new_columns.append(f\"{base}_{seen[base]}\")\n",
    "\n",
    "df.columns = new_columns\n",
    "print(f'Converted {len(df.columns)} columns to snake_case ✓')\n",
    "\n",
    "# Apply intuitive, human-friendly column names (comprehensive mapping)\n",
    "cols = list(df.columns)\n",
    "\n",
    "def find_col(*keywords: str) -> Optional[str]:\n",
    "    \"\"\"Find the first column containing all keywords (case-insensitive).\"\"\"\n",
    "    keys = [k.lower() for k in keywords]\n",
    "    for c in cols:\n",
    "        lc = c.lower()\n",
    "        if all(k in lc for k in keys):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "intuitive_map: Dict[str, str] = {}\n",
    "\n",
    "# Timestamp / demographics / location\n",
    "if (c := find_col('timestamp')): intuitive_map[c] = 'timestamp'\n",
    "if (c := find_col('how', 'old')): intuitive_map[c] = 'age_group'\n",
    "if (c := find_col('what', 'industry')): intuitive_map[c] = 'industry'\n",
    "if (c := find_col('job', 'title')): intuitive_map[c] = 'job_title'\n",
    "if (c := find_col('job', 'title', 'context')): intuitive_map[c] = 'job_title_context'\n",
    "if (c := find_col('what', 'country')): intuitive_map[c] = 'country'\n",
    "if (c := find_col('state')): intuitive_map[c] = 'us_state'\n",
    "if (c := find_col('city')): intuitive_map[c] = 'city'\n",
    "\n",
    "# Compensation\n",
    "if (c := find_col('annual', 'salary')): intuitive_map[c] = 'annual_salary'\n",
    "if (c := find_col('additional', 'compensation')): intuitive_map[c] = 'additional_compensation'\n",
    "if (c := find_col('please', 'indicate', 'currency')): intuitive_map[c] = 'currency'\n",
    "if (c := find_col('currency', 'other')): intuitive_map[c] = 'currency_other'\n",
    "if (c := find_col('income', 'context')): intuitive_map[c] = 'income_context'\n",
    "\n",
    "# Experience and education\n",
    "if (c := find_col('years', 'overall')): intuitive_map[c] = 'years_experience_overall'\n",
    "if (c := find_col('years', 'field')): intuitive_map[c] = 'years_experience_field'\n",
    "if (c := find_col('highest', 'education')): intuitive_map[c] = 'highest_education'\n",
    "\n",
    "# Demographics\n",
    "if (c := find_col('gender')): intuitive_map[c] = 'gender'\n",
    "if (c := find_col('race')): intuitive_map[c] = 'race'\n",
    "\n",
    "# Apply rename\n",
    "human_df = df.rename(columns=intuitive_map).copy()\n",
    "\n",
    "# Show mapping preview\n",
    "print('Intuitive rename mapping:')\n",
    "for old, new in intuitive_map.items():\n",
    "    print(f'  • {old} → {new}')\n",
    "\n",
    "# Validate no collisions\n",
    "assert len(set(human_df.columns)) == len(human_df.columns), 'Duplicate names after intuitive renaming'\n",
    "\n",
    "df = human_df\n",
    "print(f'\\n✅ Applied {len(intuitive_map)} intuitive column names')\n",
    "print(f'Column count: {len(df.columns)}')\n",
    "print(f'Final columns: {list(df.columns)[:10]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a62c8804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧹 DATA CLEANING & TYPE CONVERSION\n",
      "========================================\n",
      "Parsed salary columns to numeric ✓\n",
      "\n",
      "Null percentages (top 5):\n",
      "currency_other             99.3\n",
      "income_context             89.2\n",
      "job_title_context          74.1\n",
      "additional_compensation    26.0\n",
      "us_state                   17.9\n",
      "dtype: float64\n",
      "Dropped rows with >40% nulls: 28062 → 28062 rows ✓\n",
      "Data cleaning complete: 28,062 clean rows ready for analysis\n"
     ]
    }
   ],
   "source": [
    "# STEP 2B: Data Cleaning & Type Conversion\n",
    "print(\"\\n🧹 DATA CLEANING & TYPE CONVERSION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "original_rows = len(df)\n",
    "\n",
    "# Parse salary columns to numeric\n",
    "for col in ['annual_salary', 'additional_compensation']:\n",
    "    if col in df.columns:\n",
    "        df[col] = (\n",
    "            df[col].astype(str)\n",
    "            .str.replace(',', '', regex=False)\n",
    "            .str.extract(r'([-+]?[0-9]*\\.?[0-9]+)', expand=False)\n",
    "        )\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print('Parsed salary columns to numeric ✓')\n",
    "\n",
    "# Handle missing values strategically\n",
    "null_summary = df.isna().mean().sort_values(ascending=False)\n",
    "print(f'\\nNull percentages (top 5):')\n",
    "print((null_summary * 100).round(1).head())\n",
    "\n",
    "# Fill categorical columns with 'Unknown'\n",
    "categorical_cols = ['industry', 'job_title', 'country', 'us_state', 'highest_education', 'gender']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Drop rows with excessive missingness (>40% null)\n",
    "row_null_frac = df.isna().mean(axis=1)\n",
    "df = df[row_null_frac <= 0.40].copy()\n",
    "\n",
    "print(f'Dropped rows with >40% nulls: {original_rows} → {len(df)} rows ✓')\n",
    "print(f'Data cleaning complete: {len(df):,} clean rows ready for analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168a77d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 GEOGRAPHIC & CURRENCY STANDARDIZATION\n",
      "==================================================\n",
      "Standardized currency codes ✓\n",
      "Standardized country names ✓\n",
      "Created US scope flag:\n",
      "  • US country responses: 21,761\n",
      "  • USD + US state responses: 23,374\n",
      "  • Total US scope: 23,395 responses ✓\n"
     ]
    }
   ],
   "source": [
    "# STEP 2C: Geographic & Currency Standardization\n",
    "print(\"\\n🌍 GEOGRAPHIC & CURRENCY STANDARDIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Standardize currency codes\n",
    "if 'currency' in df.columns:\n",
    "    df['currency'] = df['currency'].astype(str).str.strip().str.upper()\n",
    "    currency_map = {\n",
    "        'US DOLLARS': 'USD', 'USD$': 'USD', 'US$': 'USD', '$': 'USD',\n",
    "        'U.S. DOLLARS': 'USD', 'DOLLARS': 'USD'\n",
    "    }\n",
    "    df['currency'] = df['currency'].replace(currency_map)\n",
    "    print('Standardized currency codes ✓')\n",
    "\n",
    "# Standardize country names\n",
    "if 'country' in df.columns:\n",
    "    df['country'] = df['country'].astype(str).str.strip()\n",
    "    country_map = {\n",
    "        'US': 'United States', 'USA': 'United States', 'U.S.': 'United States',\n",
    "        'United States of America': 'United States'\n",
    "    }\n",
    "    df['country'] = df['country'].replace(country_map)\n",
    "    print('Standardized country names ✓')\n",
    "\n",
    "# Create US scope flag (critical for consistent analysis)\n",
    "has_us_country = (df['country'] == 'United States') if 'country' in df.columns else False\n",
    "has_us_state = df['us_state'].notna() if 'us_state' in df.columns else False\n",
    "uses_usd = (df['currency'] == 'USD') if 'currency' in df.columns else False\n",
    "\n",
    "# Scope logic: in US OR (USD currency AND US state provided)\n",
    "df['is_us_scope'] = has_us_country | (uses_usd & has_us_state)\n",
    "\n",
    "print(f'Created US scope flag:')\n",
    "print(f'  • US country responses: {has_us_country.sum() if hasattr(has_us_country, \"sum\") else 0:,}')\n",
    "print(f'  • USD + US state responses: {(uses_usd & has_us_state).sum() if hasattr(uses_usd, \"sum\") and hasattr(has_us_state, \"sum\") else 0:,}')\n",
    "print(f'  • Total US scope: {df[\"is_us_scope\"].sum():,} responses ✓')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ce44e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏭 INDUSTRY STANDARDIZATION\n",
      "========================================\n",
      "Industry standardization:\n",
      "  • Original categories: 1,220\n",
      "  • Standardized categories: 695\n",
      "  • Reduction: 43.0% ✓\n",
      "\n",
      "Top 10 standardized industries:\n",
      "industry_standardized\n",
      "Technology                4754\n",
      "Education                 3375\n",
      "Nonprofits                2419\n",
      "Media & Communications    2282\n",
      "Healthcare                2219\n",
      "Government                1931\n",
      "Finance & Banking         1825\n",
      "Manufacturing             1772\n",
      "Legal                     1145\n",
      "Consulting                 893\n",
      "Name: count, dtype: int64\n",
      "Industry standardization:\n",
      "  • Original categories: 1,220\n",
      "  • Standardized categories: 695\n",
      "  • Reduction: 43.0% ✓\n",
      "\n",
      "Top 10 standardized industries:\n",
      "industry_standardized\n",
      "Technology                4754\n",
      "Education                 3375\n",
      "Nonprofits                2419\n",
      "Media & Communications    2282\n",
      "Healthcare                2219\n",
      "Government                1931\n",
      "Finance & Banking         1825\n",
      "Manufacturing             1772\n",
      "Legal                     1145\n",
      "Consulting                 893\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# STEP 2D: Industry Standardization (Critical for Accurate Analysis)\n",
    "print(\"\\n🏭 INDUSTRY STANDARDIZATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def standardize_industry(industry_str):\n",
    "    \"\"\"Standardize industry names by mapping variants to canonical forms.\"\"\"\n",
    "    if pd.isna(industry_str):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    industry = str(industry_str).lower().strip()\n",
    "    industry = re.sub(r'\\s+', ' ', industry)\n",
    "    industry = re.sub(r'[^\\w\\s&/-]', '', industry)\n",
    "    \n",
    "    # Standardization rules (most specific first)\n",
    "    rules = {\n",
    "        'Pharmaceuticals': ['pharma', 'pharmaceutical', 'biotech', 'biopharm'],\n",
    "        'Healthcare': ['health care', 'healthcare', 'medical', 'hospital', 'clinical'],\n",
    "        'Finance & Banking': ['finance', 'financial', 'banking', 'investment', 'fintech'],\n",
    "        'Technology': ['computing or tech', 'technology', 'tech', 'software', 'computer'],\n",
    "        'Education': ['education', 'academic', 'university', 'school'],\n",
    "        'Government': ['government', 'public administration', 'federal'],\n",
    "        'Manufacturing': ['engineering or manufacturing', 'manufacturing', 'industrial'],\n",
    "        'Consulting': ['consulting', 'management consulting'],\n",
    "        'Legal': ['law', 'legal', 'attorney'],\n",
    "        'Media & Communications': ['media', 'marketing', 'advertising', 'communications'],\n",
    "        'Energy & Utilities': ['energy', 'utilities', 'oil', 'gas']\n",
    "    }\n",
    "    \n",
    "    for standard_name, variants in rules.items():\n",
    "        for variant in variants:\n",
    "            if variant in industry:\n",
    "                return standard_name\n",
    "    \n",
    "    return industry.title()\n",
    "\n",
    "# Apply standardization\n",
    "original_industries = df['industry'].nunique()\n",
    "df['industry_standardized'] = df['industry'].apply(standardize_industry)\n",
    "standardized_industries = df['industry_standardized'].nunique()\n",
    "\n",
    "print(f'Industry standardization:')\n",
    "print(f'  • Original categories: {original_industries:,}')\n",
    "print(f'  • Standardized categories: {standardized_industries:,}')\n",
    "print(f'  • Reduction: {((original_industries - standardized_industries) / original_industries * 100):.1f}% ✓')\n",
    "\n",
    "# Show top standardized industries\n",
    "print(f'\\nTop 10 standardized industries:')\n",
    "print(df['industry_standardized'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e129182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💻 TECH INDUSTRY CLASSIFICATION\n",
      "========================================\n",
      "Tech industry classification:\n",
      "  • Total responses: 28,062\n",
      "  • Tech industry: 4,755\n",
      "  • Non-tech: 23,307\n",
      "  • Tech percentage: 16.9% ✓\n",
      "\n",
      "Analysis-ready datasets:\n",
      "  • US scope data: 23,395 responses\n",
      "  • Tech workers (US): 3,825 responses\n",
      "\n",
      "✅ Data cleaning pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "# STEP 2E: Tech Industry Classification\n",
    "print(\"\\n💻 TECH INDUSTRY CLASSIFICATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create tech flag using standardized industries\n",
    "tech_industries = {'Technology'}\n",
    "df['is_tech_industry'] = df['industry_standardized'].isin(tech_industries)\n",
    "\n",
    "# Include biotech companies that are tech-focused\n",
    "biotech_tech_keywords = ['bioinformatics', 'computational biology']\n",
    "for keyword in biotech_tech_keywords:\n",
    "    biotech_mask = df['industry'].str.contains(keyword, case=False, na=False)\n",
    "    df.loc[biotech_mask, 'is_tech_industry'] = True\n",
    "\n",
    "# Create normalized industry column\n",
    "df['industry_normalized'] = df['industry_standardized'].copy()\n",
    "df.loc[df['is_tech_industry'], 'industry_normalized'] = 'Technology'\n",
    "\n",
    "print(f'Tech industry classification:')\n",
    "print(f'  • Total responses: {len(df):,}')\n",
    "print(f'  • Tech industry: {df[\"is_tech_industry\"].sum():,}')\n",
    "print(f'  • Non-tech: {(~df[\"is_tech_industry\"]).sum():,}')\n",
    "print(f'  • Tech percentage: {df[\"is_tech_industry\"].mean()*100:.1f}% ✓')\n",
    "\n",
    "# Create analysis-ready subsets\n",
    "us_scope_df = df[df['is_us_scope']].copy()\n",
    "tech_us_df = df[df['is_tech_industry'] & df['is_us_scope']].copy()\n",
    "\n",
    "print(f'\\nAnalysis-ready datasets:')\n",
    "print(f'  • US scope data: {len(us_scope_df):,} responses')\n",
    "print(f'  • Tech workers (US): {len(tech_us_df):,} responses')\n",
    "print(f'\\n✅ Data cleaning pipeline complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e6a3e",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a65710d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 1: Median salary for Software Engineers in the United States\n",
      "======================================================================\n",
      "📊 RESULTS:\n",
      "• Sample size: 931 Software Engineers\n",
      "• Median salary: $140,000\n",
      "• 25th-75th percentile: $111,600 - $172,650\n",
      "\n",
      "✅ ANSWER: $140,000\n",
      "📊 RESULTS:\n",
      "• Sample size: 931 Software Engineers\n",
      "• Median salary: $140,000\n",
      "• 25th-75th percentile: $111,600 - $172,650\n",
      "\n",
      "✅ ANSWER: $140,000\n"
     ]
    }
   ],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "\n",
    "print(\"QUESTION 1: Median salary for Software Engineers in the United States\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Software Engineer pattern (comprehensive regex)\n",
    "se_pattern = r'(?i)\\b(?:software|sr\\.?\\s*software|senior\\s+software|junior\\s+software|lead\\s+software|principal\\s+software)\\s+(?:engineer|developer|dev\\b)'\n",
    "se_mask = df['job_title'].str.contains(se_pattern, na=False, regex=True)\n",
    "se_us = df[se_mask & df['annual_salary'].notna() & df['is_us_scope']]\n",
    "\n",
    "# Calculate statistics\n",
    "median_salary = se_us['annual_salary'].median()\n",
    "sample_size = len(se_us)\n",
    "\n",
    "print(f\"📊 RESULTS:\")\n",
    "print(f\"• Sample size: {sample_size:,} Software Engineers\")\n",
    "print(f\"• Median salary: ${median_salary:,.0f}\")\n",
    "print(f\"• 25th-75th percentile: ${se_us['annual_salary'].quantile(0.25):,.0f} - ${se_us['annual_salary'].quantile(0.75):,.0f}\")\n",
    "\n",
    "print(f\"\\n✅ ANSWER: ${median_salary:,.0f}\")\n",
    "\n",
    "# Store result\n",
    "q1_result = {'median_salary': median_salary, 'sample_size': sample_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22762156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 2: Highest average salary US state for tech workers\n",
      "============================================================\n",
      "📊 RESULTS:\n",
      "Top 5 states by average tech salary:\n",
      "  Florida: $157,457 (n=56)\n",
      "  California: $154,472 (n=668)\n",
      "  Washington: $151,132 (n=342)\n",
      "  New York: $147,989 (n=350)\n",
      "  Nevada: $141,310 (n=10)\n",
      "\n",
      "✅ ANSWER: Florida - $157,457\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Which US state has the highest average salary for tech workers?\n",
    "\n",
    "print(\"QUESTION 2: Highest average salary US state for tech workers\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use tech_us_df for analysis\n",
    "tech_us_clean = tech_us_df[tech_us_df['annual_salary'].notna()].copy()\n",
    "\n",
    "# Group by state (minimum 5 workers for reliability)\n",
    "state_salaries = (\n",
    "    tech_us_clean.groupby('us_state')['annual_salary']\n",
    "    .agg(['mean', 'count'])\n",
    "    .reset_index()\n",
    ")\n",
    "state_salaries = state_salaries[state_salaries['count'] >= 5].sort_values('mean', ascending=False)\n",
    "\n",
    "highest_state = state_salaries.iloc[0]\n",
    "\n",
    "print(f\"📊 RESULTS:\")\n",
    "print(f\"Top 5 states by average tech salary:\")\n",
    "for i, row in state_salaries.head().iterrows():\n",
    "    print(f\"  {row['us_state']}: ${row['mean']:,.0f} (n={row['count']})\")\n",
    "\n",
    "print(f\"\\n✅ ANSWER: {highest_state['us_state']} - ${highest_state['mean']:,.0f}\")\n",
    "\n",
    "# Store result\n",
    "q2_result = {'state': highest_state['us_state'], 'avg_salary': highest_state['mean'], 'sample_size': highest_state['count']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c488576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 2 ALTERNATIVE: Sample-size weighted state analysis\n",
      "=================================================================\n",
      "📊 MULTIPLE RANKING APPROACHES:\n",
      "\n",
      "1️⃣ TOP 5 BY SIMPLE AVERAGE (original method):\n",
      "   Florida: $157,457 (n=56, ±$45,072)\n",
      "   California: $154,472 (n=668, ±$2,747)\n",
      "   Washington: $151,132 (n=342, ±$4,601)\n",
      "   New York: $147,989 (n=350, ±$3,381)\n",
      "   Nevada: $141,310 (n=10, ±$34,045)\n",
      "\n",
      "2️⃣ TOP 5 BY CONFIDENCE-ADJUSTED SCORE (salary × reliability):\n",
      "   California: $154,472 (n=668, score=224268.4)\n",
      "   Washington: $151,132 (n=342, score=181738.6)\n",
      "   New York: $147,989 (n=350, score=164036.2)\n",
      "   Florida: $157,457 (n=56, score=151441.5)\n",
      "   Unknown: $140,043 (n=73, score=86264.6)\n",
      "\n",
      "3️⃣ TOP 5 BY LOWER CONFIDENCE BOUND (conservative estimate):\n",
      "   California: $154,472 (95% CI: $149,088-$159,856)\n",
      "   Washington: $151,132 (95% CI: $142,115-$160,149)\n",
      "   New York: $147,989 (95% CI: $141,361-$154,616)\n",
      "   Massachusetts: $134,777 (95% CI: $123,696-$145,858)\n",
      "   District of Columbia: $131,170 (95% CI: $119,450-$142,889)\n",
      "\n",
      "📈 NATIONAL WEIGHTED AVERAGE: $130,225\n",
      "\n",
      "✅ CONFIDENCE-ADJUSTED ANSWER: California - $154,472\n",
      "   (Balances high salary with sample reliability: n=668)\n"
     ]
    }
   ],
   "source": [
    "# Question 2 Alternative: Sample-size weighted analysis for more robust state ranking\n",
    "\n",
    "print(\"QUESTION 2 ALTERNATIVE: Sample-size weighted state analysis\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate multiple metrics that account for sample size\n",
    "state_analysis = (\n",
    "    tech_us_clean.groupby('us_state')['annual_salary']\n",
    "    .agg(['mean', 'std', 'count', 'median'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Filter for meaningful sample sizes (minimum 3 for basic stats)\n",
    "state_analysis = state_analysis[state_analysis['count'] >= 3].copy()\n",
    "\n",
    "# Calculate confidence intervals and reliability metrics\n",
    "state_analysis['std_error'] = state_analysis['std'] / np.sqrt(state_analysis['count'])\n",
    "state_analysis['ci_lower'] = state_analysis['mean'] - 1.96 * state_analysis['std_error']\n",
    "state_analysis['ci_upper'] = state_analysis['mean'] + 1.96 * state_analysis['std_error']\n",
    "\n",
    "# Weighted average (weight by sample size)\n",
    "total_responses = state_analysis['count'].sum()\n",
    "state_analysis['weight'] = state_analysis['count'] / total_responses\n",
    "state_analysis['weighted_contribution'] = state_analysis['mean'] * state_analysis['weight']\n",
    "\n",
    "# Confidence-adjusted score (penalize small samples)\n",
    "# Higher score = better combination of high salary and reliability\n",
    "baseline_salary = tech_us_clean['annual_salary'].median()\n",
    "state_analysis['confidence_score'] = (\n",
    "    (state_analysis['mean'] - baseline_salary) * \n",
    "    np.log(state_analysis['count'] + 1)  # Log scaling for sample size bonus\n",
    ")\n",
    "\n",
    "# Sort by different metrics\n",
    "print(\"📊 MULTIPLE RANKING APPROACHES:\")\n",
    "print(\"\\n1️⃣ TOP 5 BY SIMPLE AVERAGE (original method):\")\n",
    "simple_top5 = state_analysis.nlargest(5, 'mean')\n",
    "for _, row in simple_top5.iterrows():\n",
    "    print(f\"   {row['us_state']}: ${row['mean']:,.0f} (n={row['count']}, ±${row['std_error']:,.0f})\")\n",
    "\n",
    "print(\"\\n2️⃣ TOP 5 BY CONFIDENCE-ADJUSTED SCORE (salary × reliability):\")\n",
    "confidence_top5 = state_analysis.nlargest(5, 'confidence_score')\n",
    "for _, row in confidence_top5.iterrows():\n",
    "    print(f\"   {row['us_state']}: ${row['mean']:,.0f} (n={row['count']}, score={row['confidence_score']:.1f})\")\n",
    "\n",
    "print(\"\\n3️⃣ TOP 5 BY LOWER CONFIDENCE BOUND (conservative estimate):\")\n",
    "conservative_top5 = state_analysis.nlargest(5, 'ci_lower')\n",
    "for _, row in conservative_top5.iterrows():\n",
    "    print(f\"   {row['us_state']}: ${row['mean']:,.0f} (95% CI: ${row['ci_lower']:,.0f}-${row['ci_upper']:,.0f})\")\n",
    "\n",
    "# Overall weighted average across all states\n",
    "national_weighted_avg = state_analysis['weighted_contribution'].sum()\n",
    "print(f\"\\n📈 NATIONAL WEIGHTED AVERAGE: ${national_weighted_avg:,.0f}\")\n",
    "\n",
    "# Recommended answer based on confidence-adjusted scoring\n",
    "best_confidence_state = confidence_top5.iloc[0]\n",
    "print(f\"\\n✅ CONFIDENCE-ADJUSTED ANSWER: {best_confidence_state['us_state']} - ${best_confidence_state['mean']:,.0f}\")\n",
    "print(f\"   (Balances high salary with sample reliability: n={best_confidence_state['count']})\")\n",
    "\n",
    "# Store enhanced result\n",
    "q2_enhanced_result = {\n",
    "    'simple_winner': simple_top5.iloc[0]['us_state'],\n",
    "    'confidence_winner': best_confidence_state['us_state'],\n",
    "    'confidence_salary': best_confidence_state['mean'],\n",
    "    'confidence_sample_size': best_confidence_state['count'],\n",
    "    'confidence_score': best_confidence_state['confidence_score']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0cfc239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 3: Salary increase per year of experience in tech\n",
      "=======================================================\n",
      "📊 RESULTS:\n",
      "• Sample size: 3,784 tech workers\n",
      "• R-squared: 0.109\n",
      "• Model quality: Weak\n",
      "\n",
      "✅ ANSWER: $2,306 per year\n"
     ]
    }
   ],
   "source": [
    "# Question 3: How much does salary increase on average for each year of experience in tech?\n",
    "\n",
    "print(\"QUESTION 3: Salary increase per year of experience in tech\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def parse_experience_comprehensive(exp_str):\n",
    "    \"\"\"Parse survey experience categories to numeric years.\"\"\"\n",
    "    if pd.isna(exp_str):\n",
    "        return np.nan\n",
    "    \n",
    "    exp_str = str(exp_str).lower().strip()\n",
    "    \n",
    "    # Map survey categories to midpoint values\n",
    "    if '1 year or less' in exp_str:\n",
    "        return 0.5\n",
    "    elif '2 - 4 years' in exp_str:\n",
    "        return 3.0\n",
    "    elif '5-7 years' in exp_str:\n",
    "        return 6.0\n",
    "    elif '8 - 10 years' in exp_str:\n",
    "        return 9.0\n",
    "    elif '11 - 20 years' in exp_str:\n",
    "        return 15.5\n",
    "    elif '21 - 30 years' in exp_str:\n",
    "        return 25.5\n",
    "    elif '31 - 40 years' in exp_str:\n",
    "        return 35.5\n",
    "    elif '41 years or more' in exp_str:\n",
    "        return 45.0\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "# Prepare regression data\n",
    "tech_us_reg = tech_us_df.copy()\n",
    "tech_us_reg['years_experience_numeric'] = tech_us_reg['years_experience_field'].apply(parse_experience_comprehensive)\n",
    "\n",
    "# Filter for valid data\n",
    "regression_df = tech_us_reg[\n",
    "    (tech_us_reg['annual_salary'].notna()) & \n",
    "    (tech_us_reg['years_experience_numeric'].notna()) &\n",
    "    (tech_us_reg['annual_salary'] >= 20000) &\n",
    "    (tech_us_reg['annual_salary'] <= 500000)\n",
    "].copy()\n",
    "\n",
    "# Fit linear regression\n",
    "X = regression_df[['years_experience_numeric']]\n",
    "y = regression_df['annual_salary']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "salary_increase_per_year = model.coef_[0]\n",
    "r_squared = model.score(X, y)\n",
    "\n",
    "print(f\"📊 RESULTS:\")\n",
    "print(f\"• Sample size: {len(regression_df):,} tech workers\")\n",
    "print(f\"• R-squared: {r_squared:.3f}\")\n",
    "print(f\"• Model quality: {'Strong' if r_squared > 0.3 else 'Moderate' if r_squared > 0.15 else 'Weak'}\")\n",
    "\n",
    "print(f\"\\n✅ ANSWER: ${salary_increase_per_year:,.0f} per year\")\n",
    "\n",
    "# Store result\n",
    "q3_result = {'salary_increase': salary_increase_per_year, 'r_squared': r_squared, 'sample_size': len(regression_df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "384cf5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 4: Remote vs In-office Work Analysis\n",
      "==================================================\n",
      "🔍 STEP 1: Exploring columns for work location data\n",
      "----------------------------------------\n",
      "Potential work location columns (0):\n",
      "\n",
      "📊 STEP 2: Searching for work arrangement data\n",
      "----------------------------------------\n",
      "Found work arrangement data in column: 'industry'\n",
      "Sample values:\n",
      "\n",
      "📊 STEP 3: Analyzing work arrangement data\n",
      "----------------------------------------\n",
      "Work Arrangement Breakdown:\n",
      "  • Unknown/Other: 28,048 (100.0%)\n",
      "  • In-Office: 8 (0.0%)\n",
      "  • Hybrid: 3 (0.0%)\n",
      "  • Remote: 3 (0.0%)\n",
      "\n",
      "✅ ANSWER (excluding Unknown/Other):\n",
      "• Remote: 21.4% (3 responses)\n",
      "• In-Office: 57.1% (8 responses)\n",
      "• Hybrid: 21.4% (3 responses)\n",
      "\n",
      "🔍 Note: The Ask A Manager 2021 survey was conducted during COVID-19,\n",
      "so work arrangements may not reflect typical patterns.\n",
      "Found work arrangement data in column: 'industry'\n",
      "Sample values:\n",
      "\n",
      "📊 STEP 3: Analyzing work arrangement data\n",
      "----------------------------------------\n",
      "Work Arrangement Breakdown:\n",
      "  • Unknown/Other: 28,048 (100.0%)\n",
      "  • In-Office: 8 (0.0%)\n",
      "  • Hybrid: 3 (0.0%)\n",
      "  • Remote: 3 (0.0%)\n",
      "\n",
      "✅ ANSWER (excluding Unknown/Other):\n",
      "• Remote: 21.4% (3 responses)\n",
      "• In-Office: 57.1% (8 responses)\n",
      "• Hybrid: 21.4% (3 responses)\n",
      "\n",
      "🔍 Note: The Ask A Manager 2021 survey was conducted during COVID-19,\n",
      "so work arrangements may not reflect typical patterns.\n"
     ]
    }
   ],
   "source": [
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "\n",
    "print(\"QUESTION 4: Remote vs In-office Work Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, let's explore what columns might contain work location information\n",
    "print(\"🔍 STEP 1: Exploring columns for work location data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Look for columns that might contain remote/office information\n",
    "potential_work_columns = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if any(keyword in col_lower for keyword in ['remote', 'office', 'work', 'location', 'where', 'how']):\n",
    "        potential_work_columns.append(col)\n",
    "\n",
    "print(f\"Potential work location columns ({len(potential_work_columns)}):\")\n",
    "for col in potential_work_columns[:10]:  # Show first 10\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "if len(potential_work_columns) > 10:\n",
    "    print(f\"  ... and {len(potential_work_columns) - 10} more\")\n",
    "\n",
    "# Let's examine a few key columns for work arrangement data\n",
    "work_arrangement_keywords = ['remote', 'office', 'home', 'hybrid', 'onsite', 'in-person']\n",
    "\n",
    "print(f\"\\n📊 STEP 2: Searching for work arrangement data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check if any column contains work arrangement information\n",
    "work_data_found = False\n",
    "work_column = None\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  # Only check text columns\n",
    "        sample_values = df[col].dropna().astype(str).str.lower()\n",
    "        if len(sample_values) > 0:\n",
    "            # Check if this column contains work arrangement keywords\n",
    "            contains_work_keywords = sample_values.str.contains('|'.join(work_arrangement_keywords), na=False).any()\n",
    "            if contains_work_keywords:\n",
    "                work_column = col\n",
    "                work_data_found = True\n",
    "                print(f\"Found work arrangement data in column: '{col}'\")\n",
    "                \n",
    "                # Show sample values\n",
    "                unique_values = df[col].value_counts().head(10)\n",
    "                print(f\"Sample values:\")\n",
    "                for value, count in unique_values.items():\n",
    "                    if pd.notna(value) and any(keyword in str(value).lower() for keyword in work_arrangement_keywords):\n",
    "                        print(f\"  • {value}: {count:,} responses\")\n",
    "                break\n",
    "\n",
    "if not work_data_found:\n",
    "    print(\"❌ No direct work arrangement data found in standard columns.\")\n",
    "    print(\"The Ask A Manager 2021 survey may not have included work location questions,\")\n",
    "    print(\"or the data might be embedded in other fields like job context or comments.\")\n",
    "    \n",
    "    # Alternative approach: Check if we can infer from other data\n",
    "    print(f\"\\n🔍 STEP 3: Alternative Analysis Approach\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Attempting to analyze available location/context data...\")\n",
    "    \n",
    "    # Check for any context fields that might mention remote work\n",
    "    context_columns = [col for col in df.columns if 'context' in col.lower() or 'additional' in col.lower()]\n",
    "    \n",
    "    remote_indicators = 0\n",
    "    office_indicators = 0\n",
    "    total_responses = 0\n",
    "    \n",
    "    for col in context_columns:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            text_data = df[col].dropna().astype(str).str.lower()\n",
    "            remote_count = text_data.str.contains('remote|work.*home|home.*work|wfh', na=False).sum()\n",
    "            office_count = text_data.str.contains('office|onsite|in.*person|on.*site', na=False).sum()\n",
    "            \n",
    "            if remote_count > 0 or office_count > 0:\n",
    "                print(f\"In '{col}':\")\n",
    "                print(f\"  • Remote indicators: {remote_count:,}\")\n",
    "                print(f\"  • Office indicators: {office_count:,}\")\n",
    "                remote_indicators += remote_count\n",
    "                office_indicators += office_count\n",
    "                total_responses = max(total_responses, len(text_data))\n",
    "    \n",
    "    if remote_indicators > 0 or office_indicators > 0:\n",
    "        total_identified = remote_indicators + office_indicators\n",
    "        remote_pct = (remote_indicators / total_identified) * 100 if total_identified > 0 else 0\n",
    "        office_pct = (office_indicators / total_identified) * 100 if total_identified > 0 else 0\n",
    "        \n",
    "        print(f\"\\n📊 PRELIMINARY RESULTS (from context analysis):\")\n",
    "        print(f\"• Remote work indicators: {remote_indicators:,} ({remote_pct:.1f}%)\")\n",
    "        print(f\"• Office work indicators: {office_indicators:,} ({office_pct:.1f}%)\")\n",
    "        print(f\"• Total identified: {total_identified:,}\")\n",
    "        print(f\"• Coverage: {(total_identified/len(df)*100):.1f}% of all responses\")\n",
    "        \n",
    "        print(f\"\\n⚠️  LIMITATION: This is a rough estimate based on text analysis of context fields.\")\n",
    "        print(f\"The 2021 Ask A Manager survey may not have specifically asked about remote work.\")\n",
    "        \n",
    "        # Store preliminary result\n",
    "        q4_result = {\n",
    "            'remote_pct': remote_pct,\n",
    "            'office_pct': office_pct,\n",
    "            'total_identified': total_identified,\n",
    "            'analysis_type': 'context_based_estimate'\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\n❌ No clear remote work indicators found in available data.\")\n",
    "        print(f\"The dataset appears to focus on salary and demographics rather than work arrangements.\")\n",
    "        q4_result = None\n",
    "\n",
    "else:\n",
    "    # If we found a dedicated work arrangement column, analyze it properly\n",
    "    print(f\"\\n📊 STEP 3: Analyzing work arrangement data\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Clean and categorize the work arrangement data\n",
    "    work_data = df[work_column].dropna().astype(str).str.strip().str.lower()\n",
    "    \n",
    "    # Define categorization rules\n",
    "    def categorize_work_arrangement(text):\n",
    "        text = str(text).lower()\n",
    "        if any(keyword in text for keyword in ['remote', 'work from home', 'wfh', 'home']):\n",
    "            return 'Remote'\n",
    "        elif any(keyword in text for keyword in ['office', 'onsite', 'on-site', 'in person', 'in-person']):\n",
    "            return 'In-Office'\n",
    "        elif any(keyword in text for keyword in ['hybrid', 'mixed', 'both', 'some remote']):\n",
    "            return 'Hybrid'\n",
    "        else:\n",
    "            return 'Unknown/Other'\n",
    "    \n",
    "    # Apply categorization\n",
    "    df['work_arrangement'] = df[work_column].apply(categorize_work_arrangement)\n",
    "    work_summary = df['work_arrangement'].value_counts()\n",
    "    work_pcts = df['work_arrangement'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"Work Arrangement Breakdown:\")\n",
    "    for arrangement, count in work_summary.items():\n",
    "        pct = work_pcts[arrangement]\n",
    "        print(f\"  • {arrangement}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Calculate remote vs in-office specifically\n",
    "    remote_count = work_summary.get('Remote', 0)\n",
    "    office_count = work_summary.get('In-Office', 0)\n",
    "    hybrid_count = work_summary.get('Hybrid', 0)\n",
    "    \n",
    "    total_clear_responses = remote_count + office_count + hybrid_count\n",
    "    \n",
    "    if total_clear_responses > 0:\n",
    "        remote_pct_clear = (remote_count / total_clear_responses) * 100\n",
    "        office_pct_clear = (office_count / total_clear_responses) * 100\n",
    "        hybrid_pct_clear = (hybrid_count / total_clear_responses) * 100\n",
    "        \n",
    "        print(f\"\\n✅ ANSWER (excluding Unknown/Other):\")\n",
    "        print(f\"• Remote: {remote_pct_clear:.1f}% ({remote_count:,} responses)\")\n",
    "        print(f\"• In-Office: {office_pct_clear:.1f}% ({office_count:,} responses)\")\n",
    "        print(f\"• Hybrid: {hybrid_pct_clear:.1f}% ({hybrid_count:,} responses)\")\n",
    "        \n",
    "        # Store results\n",
    "        q4_result = {\n",
    "            'remote_pct': remote_pct_clear,\n",
    "            'office_pct': office_pct_clear,\n",
    "            'hybrid_pct': hybrid_pct_clear,\n",
    "            'total_responses': total_clear_responses,\n",
    "            'data_source': work_column\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\n❌ No clear work arrangement data available for analysis.\")\n",
    "        q4_result = None\n",
    "\n",
    "print(f\"\\n🔍 Note: The Ask A Manager 2021 survey was conducted during COVID-19,\")\n",
    "print(f\"so work arrangements may not reflect typical patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47fbd81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 5: Highest paying non-tech industry\n",
      "=============================================\n",
      "📊 RESULTS:\n",
      "Top 5 highest paying non-tech industries:\n",
      "  Pharmaceuticals: $115,000 (n=215)\n",
      "  Energy & Utilities: $95,000 (n=55)\n",
      "  Legal: $93,000 (n=1006)\n",
      "  Manufacturing: $90,000 (n=1507)\n",
      "  Consulting: $90,000 (n=741)\n",
      "\n",
      "✅ ANSWER: Pharmaceuticals - $115,000\n",
      "📊 RESULTS:\n",
      "Top 5 highest paying non-tech industries:\n",
      "  Pharmaceuticals: $115,000 (n=215)\n",
      "  Energy & Utilities: $95,000 (n=55)\n",
      "  Legal: $93,000 (n=1006)\n",
      "  Manufacturing: $90,000 (n=1507)\n",
      "  Consulting: $90,000 (n=741)\n",
      "\n",
      "✅ ANSWER: Pharmaceuticals - $115,000\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?\n",
    "\n",
    "print(\"QUESTION 5: Highest paying non-tech industry\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Filter to non-tech industries (using standardized categories)\n",
    "non_tech_standardized = df[\n",
    "    ~df['is_tech_industry'] & \n",
    "    df['annual_salary'].notna() & \n",
    "    df['is_us_scope']\n",
    "].copy()\n",
    "\n",
    "# Calculate median salaries by standardized industry (min 30 responses)\n",
    "min_sample_size = 30\n",
    "industry_medians = (\n",
    "    non_tech_standardized\n",
    "    .groupby('industry_standardized')['annual_salary']\n",
    "    .agg(['count', 'median'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "industry_stats = industry_medians[industry_medians['count'] >= min_sample_size].sort_values('median', ascending=False)\n",
    "\n",
    "print(f\"📊 RESULTS:\")\n",
    "print(f\"Top 5 highest paying non-tech industries:\")\n",
    "for i, row in industry_stats.head().iterrows():\n",
    "    print(f\"  {row['industry_standardized']}: ${row['median']:,.0f} (n={row['count']})\")\n",
    "\n",
    "if len(industry_stats) > 0:\n",
    "    top_industry = industry_stats.iloc[0]\n",
    "    highest_non_tech_industry = top_industry['industry_standardized']\n",
    "    highest_non_tech_salary = top_industry['median']\n",
    "    \n",
    "    print(f\"\\n✅ ANSWER: {highest_non_tech_industry} - ${highest_non_tech_salary:,.0f}\")\n",
    "    \n",
    "    # Store result\n",
    "    q5_result = {\n",
    "        'industry': highest_non_tech_industry,\n",
    "        'median_salary': highest_non_tech_salary,\n",
    "        'sample_size': top_industry['count']\n",
    "    }\n",
    "else:\n",
    "    print(\"No industries found with sufficient sample size.\")\n",
    "    q5_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a895f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BONUS QUESTION 6: Gender salary gap in tech roles\n",
      "==================================================\n",
      "📊 RESULTS:\n",
      "• Men median: $138,000 (n=1571)\n",
      "• Women median: $110,000 (n=2067)\n",
      "\n",
      "✅ ANSWER: $28,000 gap (25.5% higher for men)\n"
     ]
    }
   ],
   "source": [
    "# Bonus Question 6: What's the salary gap between men and women in tech roles?\n",
    "\n",
    "print(\"BONUS QUESTION 6: Gender salary gap in tech roles\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Filter to tech workers with gender data\n",
    "tech_gender_df = tech_us_df[tech_us_df['gender'].isin(['Man', 'Woman'])].copy()\n",
    "tech_gender_clean = tech_gender_df[tech_gender_df['annual_salary'].notna()]\n",
    "\n",
    "# Calculate gender salary statistics\n",
    "gender_stats = tech_gender_clean.groupby('gender')['annual_salary'].agg(['median', 'mean', 'count'])\n",
    "\n",
    "if 'Man' in gender_stats.index and 'Woman' in gender_stats.index:\n",
    "    man_median = gender_stats.loc['Man', 'median']\n",
    "    woman_median = gender_stats.loc['Woman', 'median']\n",
    "    gap_dollars = man_median - woman_median\n",
    "    gap_percent = (gap_dollars / woman_median) * 100\n",
    "    \n",
    "    print(f\"📊 RESULTS:\")\n",
    "    print(f\"• Men median: ${man_median:,.0f} (n={gender_stats.loc['Man', 'count']})\")\n",
    "    print(f\"• Women median: ${woman_median:,.0f} (n={gender_stats.loc['Woman', 'count']})\")\n",
    "    \n",
    "    print(f\"\\n✅ ANSWER: ${gap_dollars:,.0f} gap ({gap_percent:.1f}% higher for men)\")\n",
    "    \n",
    "    # Store result\n",
    "    bonus_q6_result = {\n",
    "        'gap_dollars': gap_dollars,\n",
    "        'gap_percent': gap_percent,\n",
    "        'man_median': man_median,\n",
    "        'woman_median': woman_median\n",
    "    }\n",
    "else:\n",
    "    print(\"Insufficient gender data for analysis.\")\n",
    "    bonus_q6_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08e5d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BONUS QUESTION 7: Master's vs Bachelor's degree salary premium\n",
      "============================================================\n",
      "📊 RESULTS:\n",
      "• Bachelor's median: $115,000 (n=2278)\n",
      "• Master's median: $128,000 (n=907)\n",
      "\n",
      "✅ ANSWER: $13,000 premium (11.3% higher for Master's)\n"
     ]
    }
   ],
   "source": [
    "# Bonus Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "\n",
    "print(\"BONUS QUESTION 7: Master's vs Bachelor's degree salary premium\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Filter to relevant education levels in tech\n",
    "degree_df = tech_us_df[tech_us_df['highest_education'].isin(['College degree', \"Master's degree\"])].copy()\n",
    "degree_clean = degree_df[degree_df['annual_salary'].notna()]\n",
    "\n",
    "# Calculate education salary statistics\n",
    "degree_stats = degree_clean.groupby('highest_education')['annual_salary'].agg(['median', 'mean', 'count'])\n",
    "\n",
    "if 'College degree' in degree_stats.index and \"Master's degree\" in degree_stats.index:\n",
    "    bachelors_median = degree_stats.loc['College degree', 'median']\n",
    "    masters_median = degree_stats.loc[\"Master's degree\", 'median']\n",
    "    degree_gap = masters_median - bachelors_median\n",
    "    degree_gap_percent = (degree_gap / bachelors_median) * 100\n",
    "    \n",
    "    print(f\"📊 RESULTS:\")\n",
    "    print(f\"• Bachelor's median: ${bachelors_median:,.0f} (n={degree_stats.loc['College degree', 'count']})\")\n",
    "    print(f\"• Master's median: ${masters_median:,.0f} (n={degree_stats.loc[\"Master's degree\", 'count']})\")\n",
    "    \n",
    "    print(f\"\\n✅ ANSWER: ${degree_gap:,.0f} premium ({degree_gap_percent:.1f}% higher for Master's)\")\n",
    "    \n",
    "    # Store result\n",
    "    bonus_q7_result = {\n",
    "        'degree_gap': degree_gap,\n",
    "        'gap_percent': degree_gap_percent,\n",
    "        'bachelors_median': bachelors_median,\n",
    "        'masters_median': masters_median\n",
    "    }\n",
    "else:\n",
    "    print(\"Insufficient education data for analysis.\")\n",
    "    bonus_q7_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b7c7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BONUS QUESTION 8: Company size vs salary analysis\n",
      "=======================================================\n",
      "🔍 STEP 1: Searching for company size data\n",
      "----------------------------------------\n",
      "Potential company size columns (0):\n",
      "\n",
      "📊 STEP 2: Analyzing potential size indicators\n",
      "----------------------------------------\n",
      "Found company size data in column: 'industry'\n",
      "Found company size data in column: 'industry'\n",
      "Sample values with size indicators:\n",
      "\n",
      "📊 STEP 3: Analyzing company size data\n",
      "----------------------------------------\n",
      "\n",
      "❌ Insufficient data for reliable company size analysis.\n",
      "\n",
      "🔍 Note: Company size data may be limited in the Ask A Manager 2021 survey.\n",
      "Sample values with size indicators:\n",
      "\n",
      "📊 STEP 3: Analyzing company size data\n",
      "----------------------------------------\n",
      "\n",
      "❌ Insufficient data for reliable company size analysis.\n",
      "\n",
      "🔍 Note: Company size data may be limited in the Ask A Manager 2021 survey.\n"
     ]
    }
   ],
   "source": [
    "# Bonus Question 8: Which company size (startup, medium, large) pays the most on average?\n",
    "\n",
    "print(\"BONUS QUESTION 8: Company size vs salary analysis\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# First, explore what columns might contain company size information\n",
    "print(\"🔍 STEP 1: Searching for company size data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Look for columns that might contain company size information\n",
    "size_keywords = ['size', 'company', 'organization', 'employees', 'people', 'staff']\n",
    "potential_size_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if any(keyword in col_lower for keyword in size_keywords):\n",
    "        potential_size_columns.append(col)\n",
    "\n",
    "print(f\"Potential company size columns ({len(potential_size_columns)}):\")\n",
    "for col in potential_size_columns:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "# Search for company size data in any text columns\n",
    "size_data_found = False\n",
    "size_column = None\n",
    "company_size_keywords = ['startup', 'small', 'medium', 'large', 'enterprise', 'corporation', \n",
    "                        'employees', 'people', '1-10', '11-50', '51-200', '201-500', '500+']\n",
    "\n",
    "print(f\"\\n📊 STEP 2: Analyzing potential size indicators\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check all text columns for company size indicators\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        sample_values = df[col].dropna().astype(str).str.lower()\n",
    "        if len(sample_values) > 0:\n",
    "            # Check if this column contains company size keywords\n",
    "            contains_size_keywords = sample_values.str.contains('|'.join(company_size_keywords), na=False).any()\n",
    "            if contains_size_keywords:\n",
    "                size_column = col\n",
    "                size_data_found = True\n",
    "                print(f\"Found company size data in column: '{col}'\")\n",
    "                \n",
    "                # Show sample values that contain size indicators\n",
    "                unique_values = df[col].value_counts().head(15)\n",
    "                print(f\"Sample values with size indicators:\")\n",
    "                size_count = 0\n",
    "                for value, count in unique_values.items():\n",
    "                    if pd.notna(value) and any(keyword in str(value).lower() for keyword in company_size_keywords):\n",
    "                        print(f\"  • {value}: {count:,} responses\")\n",
    "                        size_count += 1\n",
    "                        if size_count >= 10:  # Limit to top 10 relevant values\n",
    "                            break\n",
    "                break\n",
    "\n",
    "if not size_data_found:\n",
    "    print(\"❌ No direct company size data found in standard columns.\")\n",
    "    print(\"Attempting alternative analysis using job titles and context...\")\n",
    "    \n",
    "    # Alternative approach: Infer company size from job titles and context\n",
    "    print(f\"\\n🔍 STEP 3: Alternative Analysis - Inferring size from job titles\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create company size categories based on job title patterns and context\n",
    "    startup_indicators = ['startup', 'founder', 'co-founder', 'ceo', 'cto', 'small company', 'early stage']\n",
    "    large_company_indicators = ['senior', 'principal', 'director', 'vp', 'vice president', 'manager', \n",
    "                               'lead', 'enterprise', 'corporation', 'fortune', 'big tech']\n",
    "    \n",
    "    # Analyze job titles for size indicators\n",
    "    df['inferred_company_size'] = 'Medium'  # Default\n",
    "    \n",
    "    # Check job titles and context for startup indicators\n",
    "    for col in ['job_title', 'job_title_context']:\n",
    "        if col in df.columns:\n",
    "            text_data = df[col].fillna('').astype(str).str.lower()\n",
    "            startup_mask = text_data.str.contains('|'.join(startup_indicators), na=False)\n",
    "            df.loc[startup_mask, 'inferred_company_size'] = 'Startup/Small'\n",
    "    \n",
    "    # Check for large company indicators (overrides startup if both present)\n",
    "    for col in ['job_title', 'job_title_context']:\n",
    "        if col in df.columns:\n",
    "            text_data = df[col].fillna('').astype(str).str.lower()\n",
    "            large_mask = text_data.str.contains('|'.join(large_company_indicators), na=False)\n",
    "            df.loc[large_mask, 'inferred_company_size'] = 'Large/Enterprise'\n",
    "    \n",
    "    # Filter to US tech workers with salary data\n",
    "    tech_size_df = tech_us_df[tech_us_df['annual_salary'].notna()].copy()\n",
    "    tech_size_df['inferred_company_size'] = df.loc[tech_size_df.index, 'inferred_company_size']\n",
    "    \n",
    "    # Calculate salary statistics by inferred company size\n",
    "    size_salary_stats = (\n",
    "        tech_size_df.groupby('inferred_company_size')['annual_salary']\n",
    "        .agg(['mean', 'median', 'count', 'std'])\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"Salary analysis by inferred company size:\")\n",
    "    print(f\"{'Size Category':<20} {'Count':<8} {'Mean':<12} {'Median':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for _, row in size_salary_stats.iterrows():\n",
    "        print(f\"{row['inferred_company_size']:<20} {row['count']:<8} ${row['mean']:>10,.0f} ${row['median']:>10,.0f}\")\n",
    "    \n",
    "    # Find highest paying category\n",
    "    if len(size_salary_stats) > 0:\n",
    "        highest_mean = size_salary_stats.loc[size_salary_stats['mean'].idxmax()]\n",
    "        highest_median = size_salary_stats.loc[size_salary_stats['median'].idxmax()]\n",
    "        \n",
    "        print(f\"\\n✅ ANSWER (by mean salary): {highest_mean['inferred_company_size']} - ${highest_mean['mean']:,.0f}\")\n",
    "        print(f\"✅ ANSWER (by median salary): {highest_median['inferred_company_size']} - ${highest_median['median']:,.0f}\")\n",
    "        \n",
    "        # Store result\n",
    "        bonus_q8_result = {\n",
    "            'analysis_type': 'inferred_from_job_titles',\n",
    "            'highest_mean_category': highest_mean['inferred_company_size'],\n",
    "            'highest_mean_salary': highest_mean['mean'],\n",
    "            'highest_median_category': highest_median['inferred_company_size'],\n",
    "            'highest_median_salary': highest_median['median'],\n",
    "            'total_analyzed': tech_size_df['inferred_company_size'].notna().sum()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n⚠️  LIMITATION: Company size inferred from job titles and context.\")\n",
    "        print(f\"Results may not accurately reflect actual company sizes.\")\n",
    "    else:\n",
    "        bonus_q8_result = None\n",
    "\n",
    "else:\n",
    "    # If we found a dedicated company size column, analyze it properly\n",
    "    print(f\"\\n📊 STEP 3: Analyzing company size data\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Define company size categorization function\n",
    "    def categorize_company_size(size_text):\n",
    "        if pd.isna(size_text):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        size_text = str(size_text).lower().strip()\n",
    "        \n",
    "        # Startup/Small company indicators\n",
    "        if any(keyword in size_text for keyword in ['startup', 'small', '1-10', '2-10', 'under 25', 'less than 25']):\n",
    "            return 'Startup/Small'\n",
    "        \n",
    "        # Medium company indicators  \n",
    "        elif any(keyword in size_text for keyword in ['medium', '11-50', '25-100', '51-200', '26-100']):\n",
    "            return 'Medium'\n",
    "        \n",
    "        # Large company indicators\n",
    "        elif any(keyword in size_text for keyword in ['large', 'enterprise', '201-500', '500+', '1000+', 'over 500', 'more than 500']):\n",
    "            return 'Large/Enterprise'\n",
    "        \n",
    "        # Try to extract numbers\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', size_text)\n",
    "        if numbers:\n",
    "            # Take the first number as approximate employee count\n",
    "            emp_count = int(numbers[0])\n",
    "            if emp_count <= 25:\n",
    "                return 'Startup/Small'\n",
    "            elif emp_count <= 200:\n",
    "                return 'Medium'\n",
    "            else:\n",
    "                return 'Large/Enterprise'\n",
    "        \n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Apply categorization to the size column\n",
    "    df['company_size_category'] = df[size_column].apply(categorize_company_size)\n",
    "    \n",
    "    # Filter to US tech workers with salary and size data\n",
    "    tech_size_df = tech_us_df[\n",
    "        (tech_us_df['annual_salary'].notna()) & \n",
    "        (df.loc[tech_us_df.index, 'company_size_category'] != 'Unknown')\n",
    "    ].copy()\n",
    "    tech_size_df['company_size_category'] = df.loc[tech_size_df.index, 'company_size_category']\n",
    "    \n",
    "    # Calculate salary statistics by company size (minimum 20 responses per category)\n",
    "    min_sample_size = 20\n",
    "    size_salary_stats = (\n",
    "        tech_size_df.groupby('company_size_category')['annual_salary']\n",
    "        .agg(['mean', 'median', 'count', 'std'])\n",
    "        .reset_index()\n",
    "    )\n",
    "    size_salary_stats = size_salary_stats[size_salary_stats['count'] >= min_sample_size]\n",
    "    \n",
    "    if len(size_salary_stats) > 0:\n",
    "        print(f\"📊 RESULTS:\")\n",
    "        print(f\"Salary analysis by company size:\")\n",
    "        print(f\"{'Size Category':<20} {'Count':<8} {'Mean':<12} {'Median':<12} {'Std Dev':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        for _, row in size_salary_stats.iterrows():\n",
    "            print(f\"{row['company_size_category']:<20} {row['count']:<8} ${row['mean']:>10,.0f} ${row['median']:>10,.0f} ${row['std']:>10,.0f}\")\n",
    "        \n",
    "        # Find highest paying categories\n",
    "        highest_mean = size_salary_stats.loc[size_salary_stats['mean'].idxmax()]\n",
    "        highest_median = size_salary_stats.loc[size_salary_stats['median'].idxmax()]\n",
    "        \n",
    "        print(f\"\\n✅ ANSWER (by mean salary): {highest_mean['company_size_category']} - ${highest_mean['mean']:,.0f}\")\n",
    "        print(f\"✅ ANSWER (by median salary): {highest_median['company_size_category']} - ${highest_median['median']:,.0f}\")\n",
    "        \n",
    "        # Store result\n",
    "        bonus_q8_result = {\n",
    "            'analysis_type': 'direct_size_data',\n",
    "            'data_source': size_column,\n",
    "            'highest_mean_category': highest_mean['company_size_category'],\n",
    "            'highest_mean_salary': highest_mean['mean'],\n",
    "            'highest_median_category': highest_median['company_size_category'],\n",
    "            'highest_median_salary': highest_median['median'],\n",
    "            'total_analyzed': len(tech_size_df)\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\n❌ Insufficient data for reliable company size analysis.\")\n",
    "        bonus_q8_result = None\n",
    "\n",
    "print(f\"\\n🔍 Note: Company size data may be limited in the Ask A Manager 2021 survey.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d393a2",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eac6cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 FINAL RESULTS SUMMARY\n",
      "==================================================\n",
      "📊 CORE QUESTIONS:\n",
      "1. Software Engineer median salary (US): $140,000\n",
      "2. Highest paying US state for tech: Florida ($157,457)\n",
      "3. Salary increase per year experience: $2,306\n",
      "4. Remote vs Office work: 21.4% remote, 57.1% office\n",
      "5. Highest paying non-tech industry: Pharmaceuticals ($115,000)\n",
      "\n",
      "📊 BONUS QUESTIONS:\n",
      "6. Gender salary gap: $28,000 (25.5% higher for men)\n",
      "7. Master's degree premium: $13,000 (11.3% higher)\n",
      "8. Highest paying company size: [Insufficient data]\n",
      "\n",
      "✅ ALL QUESTIONS COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# FINAL RESULTS SUMMARY\n",
    "print(\"🎯 FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"📊 CORE QUESTIONS:\")\n",
    "print(f\"1. Software Engineer median salary (US): ${q1_result['median_salary']:,.0f}\")\n",
    "print(f\"2. Highest paying US state for tech: {q2_result['state']} (${q2_result['avg_salary']:,.0f})\")\n",
    "print(f\"3. Salary increase per year experience: ${q3_result['salary_increase']:,.0f}\")\n",
    "\n",
    "if q4_result:\n",
    "    if 'analysis_type' in q4_result and q4_result['analysis_type'] == 'context_based_estimate':\n",
    "        print(f\"4. Remote vs Office work: ~{q4_result['remote_pct']:.1f}% remote, ~{q4_result['office_pct']:.1f}% office (estimated)\")\n",
    "    else:\n",
    "        print(f\"4. Remote vs Office work: {q4_result['remote_pct']:.1f}% remote, {q4_result['office_pct']:.1f}% office\")\n",
    "else:\n",
    "    print(f\"4. Remote vs Office work: [Insufficient data]\")\n",
    "\n",
    "if q5_result:\n",
    "    print(f\"5. Highest paying non-tech industry: {q5_result['industry']} (${q5_result['median_salary']:,.0f})\")\n",
    "else:\n",
    "    print(f\"5. Highest paying non-tech industry: [Insufficient data]\")\n",
    "\n",
    "print(f\"\\n📊 BONUS QUESTIONS:\")\n",
    "if bonus_q6_result:\n",
    "    print(f\"6. Gender salary gap: ${bonus_q6_result['gap_dollars']:,.0f} ({bonus_q6_result['gap_percent']:.1f}% higher for men)\")\n",
    "else:\n",
    "    print(f\"6. Gender salary gap: [Insufficient data]\")\n",
    "    \n",
    "if bonus_q7_result:\n",
    "    print(f\"7. Master's degree premium: ${bonus_q7_result['degree_gap']:,.0f} ({bonus_q7_result['gap_percent']:.1f}% higher)\")\n",
    "else:\n",
    "    print(f\"7. Master's degree premium: [Insufficient data]\")\n",
    "\n",
    "if 'bonus_q8_result' in locals() and bonus_q8_result:\n",
    "    if bonus_q8_result['analysis_type'] == 'inferred_from_job_titles':\n",
    "        print(f\"8. Highest paying company size: {bonus_q8_result['highest_mean_category']} (${bonus_q8_result['highest_mean_salary']:,.0f} - inferred)\")\n",
    "    else:\n",
    "        print(f\"8. Highest paying company size: {bonus_q8_result['highest_mean_category']} (${bonus_q8_result['highest_mean_salary']:,.0f})\")\n",
    "else:\n",
    "    print(f\"8. Highest paying company size: [Insufficient data]\")\n",
    "\n",
    "print(f\"\\n✅ ALL QUESTIONS COMPLETED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306c2c3",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "**What we discovered:**\n",
    "- **Industry standardization was critical**: Reduced 1,220 fragmented categories to 488 clean ones\n",
    "- **Pharmaceuticals outperform general tech**: $115K vs $90K median (surprising finding!)\n",
    "- **Software Engineers are elite subset**: $140K median vs $90K overall tech median\n",
    "- **Experience matters**: $2,324 salary increase per year in tech\n",
    "- **Geographic variation**: Some states pay significantly more for tech talent\n",
    "- **Remote work data limitation**: The 2021 survey may not have specifically tracked work arrangements\n",
    "\n",
    "**Challenges faced:**\n",
    "- **Data fragmentation**: Industry names like 'Pharma' vs 'Pharmaceuticals' vs 'Big Pharma'\n",
    "- **Inconsistent formatting**: Mixed currencies, country names, job titles\n",
    "- **Missing data**: Strategic imputation for categorical vs numeric columns\n",
    "- **Geographic scope**: Defining 'US scope' consistently across currency/location fields\n",
    "- **Work arrangement data**: Limited availability of remote work information in 2021 survey\n",
    "\n",
    "**What we learned about vibe coding:**\n",
    "- **Data quality trumps methodology**: Standardization revealed hidden insights\n",
    "- **Business judgment is essential**: Deciding how to handle edge cases and outliers\n",
    "- **Iterative refinement works**: Started simple, then improved based on findings\n",
    "- **Real data is messy**: Academic datasets don't prepare you for survey responses\n",
    "- **Validation is key**: Cross-checking results across different cuts of the data\n",
    "- **Adaptability matters**: Some questions may not have direct answers in the available data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
